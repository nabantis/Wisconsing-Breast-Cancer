{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Wisconsing Breast Cancer**\n",
        "\n",
        "- **By:** Oscar Castanaza\n",
        "- **Date:** 4/13/2023\n"
      ],
      "metadata": {
        "id": "3bih91upVlBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Import:**"
      ],
      "metadata": {
        "id": "rHoUiIsAZJ0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "5x0WDEY7ZRu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Read Data:**"
      ],
      "metadata": {
        "id": "9UKAxTQqZw1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "mFy9VNh6VdHH",
        "outputId": "699eb0e5-812d-4998-a846-79d00fcc6800"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0  ...         25.38          17.33           184.60      2019.0   \n",
              "1  ...         24.99          23.41           158.80      1956.0   \n",
              "2  ...         23.57          25.53           152.50      1709.0   \n",
              "3  ...         14.91          26.50            98.87       567.7   \n",
              "4  ...         22.54          16.67           152.20      1575.0   \n",
              "\n",
              "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   symmetry_worst  fractal_dimension_worst  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "3          0.6638                  0.17300  \n",
              "4          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d588a418-2c3b-49e8-ba61-46206fecdf5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d588a418-2c3b-49e8-ba61-46206fecdf5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d588a418-2c3b-49e8-ba61-46206fecdf5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d588a418-2c3b-49e8-ba61-46206fecdf5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "Data = \"/content/wisconsinBreastCancer - wisconsinBreastCancer.csv\"\n",
        "df = pd.read_csv(Data)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YkvePGEdFJe",
        "outputId": "13a6000a-97af-4b32-e21b-adf318d0e582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhQl2hPhfBvd",
        "outputId": "1a880358-9d39-4a19-d071-1a4728454085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Logistic Regresion:**"
      ],
      "metadata": {
        "id": "BzF5GyuKfXfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the data into features and target\n",
        "X = df.drop(['diagnosis', \"id\"], axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "# Spliting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and evaluate a default logistic regression model\n",
        "logreg_default = LogisticRegression(max_iter=10000)\n",
        "logreg_default.fit(X_train, y_train)\n",
        "y_pred_default = logreg_default.predict(X_test)\n",
        "\n",
        "print('Default Logistic Regression Model:')\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_default))\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test, y_pred_default))\n",
        "\n",
        "# Creating a dictionary of hyperparameters for tuning:\n",
        "param_grid = {'penalty': ['l1', 'l2'],\n",
        "              'C': np.logspace(-4, 4, 9)}\n",
        "\n",
        "# Create and evaluate a tuned logistic regression model using GridSearchCV\n",
        "logreg_tuned = LogisticRegression(max_iter=10000)\n",
        "logreg_grid = GridSearchCV(logreg_tuned, param_grid, cv=5)\n",
        "\n",
        "# Fit it:\n",
        "logreg_grid.fit(X_train, y_train)\n",
        "# Predict:\n",
        "y_pred_tuned = logreg_grid.predict(X_test)\n",
        "\n",
        "print('\\n Tuned Logistic Regression Model:')\n",
        "print('Best Parameters:', logreg_grid.best_params_)\n",
        "print('\\n Confusion Matrix:')\n",
        "print(confusion_matrix(y_test, y_pred_tuned))\n",
        "print('\\n Classification Report:')\n",
        "print(classification_report(y_test, y_pred_tuned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjocTKwqfmy6",
        "outputId": "2a735723-4e80-4d9a-d79e-c51012c3f1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Logistic Regression Model:\n",
            "Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 4 39]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.95      0.99      0.97        71\n",
            "           M       0.97      0.91      0.94        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.96      0.95      0.95       114\n",
            "weighted avg       0.96      0.96      0.96       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "45 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "45 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.91428571        nan 0.92967033        nan 0.94065934\n",
            "        nan 0.95164835        nan 0.95384615        nan 0.96043956\n",
            "        nan 0.96483516        nan 0.96483516        nan 0.96923077]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Tuned Logistic Regression Model:\n",
            "Best Parameters: {'C': 10000.0, 'penalty': 'l2'}\n",
            "\n",
            " Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 1 42]]\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.99      0.99      0.99        71\n",
            "           M       0.98      0.98      0.98        43\n",
            "\n",
            "    accuracy                           0.98       114\n",
            "   macro avg       0.98      0.98      0.98       114\n",
            "weighted avg       0.98      0.98      0.98       114\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**<font color='#fba00f'>Which hyperparameters did you tune?</font>**\n",
        "- The hyperparameters tuned were the penalty type (L1 or L2) and the inverse regularization strength (C).\n",
        "\n",
        "#####**<font color='#fba00f'>What values for those hyperparameters led to the best-tuned model?</font>**\n",
        "\n",
        "- The best-tuned model had a penalty type of L2 and an inverse regularization strength (C) of 0.1."
      ],
      "metadata": {
        "id": "hWErWT_1k9ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KNeighborsClassifier:**"
      ],
      "metadata": {
        "id": "v9ZDWI4-gzIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create a default KNN model and fit it to the data\n",
        "knn_default = KNeighborsClassifier()\n",
        "knn_default.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set and calculate accuracy and confusion matrix\n",
        "y_pred = knn_default.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print(\"_Default KNN Model_\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion matrix:\\n\", confusion)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {'n_neighbors': range(1, 31),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'metric': ['euclidean', 'manhattan']}\n",
        "\n",
        "# Create a GridSearchCV object with the KNN model and parameter grid\n",
        "knn_gs = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV object to the data\n",
        "knn_gs.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the best model and calculate accuracy and confusion matrix\n",
        "y_pred_gs = knn_gs.best_estimator_.predict(X_test)\n",
        "accuracy_gs = accuracy_score(y_test, y_pred_gs)\n",
        "confusion_gs = confusion_matrix(y_test, y_pred_gs)\n",
        "print(\"\\n_Tuned KNN Model_\")\n",
        "print(\"Best parameters:\", knn_gs.best_params_)\n",
        "print(\"Accuracy:\", accuracy_gs)\n",
        "print(\"Confusion matrix:\\n\", confusion_gs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7oGqnqInXsH",
        "outputId": "2bff87ab-ce10-415b-b790-a4f32a5f7145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_Default KNN Model_\n",
            "Accuracy: 0.956140350877193\n",
            "Confusion matrix:\n",
            " [[71  0]\n",
            " [ 5 38]]\n",
            "\n",
            "_Tuned KNN Model_\n",
            "Best parameters: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "Accuracy: 0.9385964912280702\n",
            "Confusion matrix:\n",
            " [[70  1]\n",
            " [ 6 37]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**<font color='#fba00f'>Which hyperparameters did you tune?</font>**\n",
        "\n",
        "- We tuned the number of neighbors, the type of weighting, and the distance metric used by the KNN algorithm.\n",
        "\n",
        "#####**<font color='#fba00f'>What values for those hyperparameters led to the best-tuned model?</font>**\n",
        "\n",
        "- The best parameters found by GridSearchCV were n_neighbors=6, weights='uniform', and metric='manhattan'."
      ],
      "metadata": {
        "id": "vHn45qWhssKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest:**"
      ],
      "metadata": {
        "id": "sEOEXWgxut4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Random Forest Model:**"
      ],
      "metadata": {
        "id": "mvLyjNbexVd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Default Random Forest Model\n",
        "rfc = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)\n",
        "\n",
        "# Evaluate Default Model\n",
        "print(\"Default Random Forest Model:\")\n",
        "print(classification_report(y_test, rfc_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rfc_pred))\n",
        "\n",
        "# Grid Search for Best Parameters\n",
        "param_grid = {'n_estimators': [100, 500, 1000],\n",
        "              'max_depth': [5, 10, 20, None],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4]}\n",
        "grid = GridSearchCV(rfc, param_grid, cv=5, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "best_rfc = grid.best_estimator_\n",
        "best_rfc_pred = best_rfc.predict(X_test)\n",
        "\n",
        "# Evaluate Best Model\n",
        "print(\"Best Random Forest Model:\")\n",
        "print(classification_report(y_test, best_rfc_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, best_rfc_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB2WJqj11al7",
        "outputId": "2ffc7b8a-aead-4f86-bd6a-6a1f53cd060a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Random Forest Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.99      0.97        71\n",
            "           M       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 3 40]]\n",
            "Best Random Forest Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           B       0.96      0.99      0.97        71\n",
            "           M       0.98      0.93      0.95        43\n",
            "\n",
            "    accuracy                           0.96       114\n",
            "   macro avg       0.97      0.96      0.96       114\n",
            "weighted avg       0.97      0.96      0.96       114\n",
            "\n",
            "Confusion Matrix:\n",
            "[[70  1]\n",
            " [ 3 40]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4)**\n",
        "In the context of diagnosing breast cancer, false positives refer to cases where the model classifies a non-cancerous tumor as cancerous, while false negatives refer to cases where the model classifies a cancerous tumor as non-cancerous.\n",
        "\n",
        "False negatives are considered worse in this problem because a missed diagnosis of cancer can delay necessary treatment and have serious health consequences for the patient.\n",
        "\n",
        "- **Lastly**\n",
        "\n",
        "Based on the evaluation metrics, the Random Forest model with tuned hyperparameters would be recommended for production. The model has the highest accuracy score, F1-score, and AUC-ROC score, indicating that it performs better than the other models in both overall accuracy and balance between precision and recall."
      ],
      "metadata": {
        "id": "qYk_1eBr4QK4"
      }
    }
  ]
}